---
title: 'Week 10: Model Evaluation'
author: ShuXin Ho
date: '2024-11-17'
slug: week-10
categories: []
tags: []
output: 
  blogdown::html_page:
    mathjax: true
---

```{r, echo = FALSE, message = FALSE, warning = FALSE}
# Code developed with assistance from ChatGPT.

# Load libraries.
library(censable)
library(geofacet)
library(ggpubr)
library(ggthemes)
library(haven)
library(kableExtra)
library(maps)
library(mgcv)
library(mgcViz)
library(RColorBrewer)
library(readstata13)
library(scales)
library(sf)
library(spData)
library(stargazer)
library(tidygeocoder)
library(tidyverse)
library(tigris)
library(tmap)
library(tmaptools)
library(viridis)
library(car)
library(caret)
library(CVXR)
library(glmnet)
library(Metrics)
library(ranger)
library(janitor)
library(Matrix)
library(nlme)
library(blogdown)

### Read, merge, and process data.
# Read 2024 results datasets. 
d_state_2024 <- read_csv("state_votes_pres_2024.csv")[-1, 1:6]
d_county_2024 <- read_csv("county_votes_pres_2024.csv")[-1, 1:6]
d_county_2020 <- read_csv("county_votes_pres_2020.csv")[-1, 1:6]
  
# Process 2024 state and county-level data. 
d_state_2024 <- d_state_2024 %>% 
  mutate(FIPS = as.numeric(FIPS), 
         votes_trump = as.numeric(`Donald J. Trump`), 
         votes_harris = as.numeric(`Kamala D. Harris`), 
         votes = as.numeric(`Total Vote`),
         trump_pv = votes_trump/votes, 
         harris_pv = votes_harris/votes, 
         trump_2pv = votes_trump/(votes_trump + votes_harris), 
         harris_2pv = votes_harris/(votes_trump + votes_harris)) %>% 
  mutate(winner = case_when(votes_trump > votes_harris ~ "Republican", 
                            .default = "Democrat"))

d_county_2024 <- d_county_2024 %>%
  mutate(FIPS = as.numeric(FIPS),
         votes_trump = as.numeric(`Donald J. Trump`), 
         votes_harris = as.numeric(`Kamala D. Harris`), 
         votes = as.numeric(`Total Vote`), 
         trump_pv = votes_trump/votes, 
         harris_pv = votes_harris/votes, 
         trump_2pv = votes_trump/(votes_trump + votes_harris), 
         harris_2pv = votes_harris/(votes_trump + votes_harris)) %>% 
  mutate(winner = case_when(votes_trump > votes_harris ~ "Republican", 
                            .default = "Democrat")) %>% 
  select(FIPS, `Geographic Name`, `Geographic Subtype`, votes_trump, votes_harris, votes, 
         winner, trump_pv, harris_pv, trump_2pv, harris_2pv)

d_county_2020 <- d_county_2020 %>% 
  mutate(FIPS = as.numeric(FIPS),
         votes_trump_2020 = as.numeric(`Donald J. Trump`), 
         votes_biden_2020 = as.numeric(`Joseph R. Biden Jr.`), 
         votes_2020 = as.numeric(`Total Vote`), 
         trump_pv_2020 = votes_trump_2020/votes_2020, 
         biden_pv_2020 = votes_biden_2020/votes_2020, 
         trump_2pv_2020 = votes_trump_2020/(votes_trump_2020 + votes_biden_2020), 
         biden_2pv_2020 = votes_biden_2020/(votes_trump_2020 + votes_biden_2020)) %>% 
  mutate(winner_2020 = case_when(votes_trump_2020 > votes_biden_2020 ~ "Republican", 
                            .default = "Democrat")) %>% 
  select(FIPS, `Geographic Name`, `Geographic Subtype`, votes_trump_2020, votes_biden_2020, votes_2020, 
         winner_2020, trump_pv_2020, biden_pv_2020, trump_2pv_2020, biden_2pv_2020)
```

# Election Blog

## Week 10: Model Evaluation

### Recap of My Model and Predictions

Prior to the 2024 presidential election, I developed a weighted ensemble model using super learning. The weights for this ensemble were determined from the out-of-sample performance of multiple OLS models incorporating various predictor variables, including lagged vote share, economic indicators, polling data, demographic variables, incumbency consideration, and their combinations.

My final forecast predicted Kamala Harris would win the national two-party popular vote with 56.76%, but lose the Electoral College vote, securing only 226 votes. The model accurately predicted the results of the battleground states, including Arizona, Georgia, Michigan, Nevada, North Carolina, Pennsylvania, and Wisconsin, all of which voted for Donald Trump.

### Electoral College Vote Share Evaluation

Below is the electoral college map showing the election outcome, which matched my model's predictions.

```{r, echo = FALSE, message = FALSE, warning = FALSE, results = "hide", fig.show = "hide"}
### Visualizing the results of the 2024 Presidential Election. 
# Sequester state and county-level map.
options(progress = FALSE)

states_2024 <- states(cb = TRUE, year = 2023) %>% 
  shift_geometry() %>% 
  mutate(GEOID = as.numeric(GEOID)) %>% 
  left_join(d_state_2024, by = c("GEOID" = "FIPS")) %>% 
  drop_na()

counties_2024 <- counties(cb = TRUE, resolution = "5m", year = 2023) %>% 
  shift_geometry() %>% 
  mutate(GEOID = as.numeric(GEOID)) %>% 
  left_join(d_county_2024, by = c("GEOID" = "FIPS")) %>% 
  left_join(d_county_2020, by = c("GEOID" = "FIPS")) %>%
  mutate(shift = (trump_pv - trump_pv_2020) * 100, 
         shift_dir = case_when(shift > 0 ~ "Republican", 
                               shift < 0 ~ "Democrat", 
                               TRUE ~ "No Change"),
         centroid = st_centroid(geometry), 
         centroid_long = st_coordinates(centroid)[,1],
         centroid_lat = st_coordinates(centroid)[,2],
         scale_factor = 1e4, 
         end_long = centroid_long + scale_factor * shift,
         end_lat = centroid_lat + scale_factor * shift) %>%
  drop_na()

county_pop_2024 <- read_csv("PopulationEstimates.csv") %>% 
  mutate(FIPStxt = as.numeric(FIPStxt)) %>%
  select(FIPStxt, POP_ESTIMATE_2023)
counties_2024 <- counties_2024 %>% 
  left_join(county_pop_2024, by = c("GEOID" = "FIPStxt"))
```

```{r, echo = FALSE, message = FALSE, warning = FALSE}
# Make map of state winners. 
ggplot(states_2024, aes(fill = factor(winner))) + 
  geom_sf() + 
  scale_fill_manual(values = c("Democrat" = "dodgerblue4", "Republican" = "firebrick3")) + 
  theme_minimal() + 
  labs(title = "2024 Presidential Election Results by State", 
       fill = "Winner") + 
  theme(legend.position = "bottom")
```

The following bubble map illustrates county-level results by total number of votes casted in each county, to better visualize the vote distribution. Democratic vote share is concentrated in highly populated urban areas, while Republican vote share cover a broader geographic area, as shown by the widespread red bubbles.

```{r, echo = FALSE, message = FALSE, warning = FALSE}
# Make bubble map of county-level results for the US for 2024. 
counties_2024 %>% 
  ggplot() + 
  geom_sf(fill = "gray95", color = "darkgrey") +  # Base map
  geom_point(aes(x = centroid_long, y = centroid_lat, size = votes, color = factor(winner)),
             alpha = 0.5) +  # Semi-transparent bubbles
  scale_size_continuous(range = c(1, 10), breaks = c(10000, 100000, 500000, 1000000),
                        labels = scales::comma) +  # Scale bubble size proportionally to vote count
  scale_color_manual(values = c("Democrat" = "dodgerblue4", "Republican" = "firebrick3")) +  # Color by party
  theme_minimal() +
  labs(title = "2024 Presidential Election Results by County",
       subtitle = "(Bubble size represents total votes casted)",
       size = "Total Votes",
       color = "Winner") +
  theme(legend.position = "right",
        axis.title = element_blank())
```

My prediction error for each state is demonstrated in the graph below. All values still result in the correct prediction for the party winner of each state's two-party popular vote.

```{r, echo = FALSE, message = FALSE, warning = FALSE}
state_predictions <- read_csv("state_predictions.csv")

state_predictions <- state_predictions %>% 
  left_join(d_state_2024, by = c("state" = "Geographic Name", "winner")) %>% 
  mutate(bias = 100*harris_2pv - Democrat) %>% 
  arrange(state)

ggplot(state_predictions, aes(x = reorder(state, bias), y = bias, fill = bias)) +
  geom_col() + 
  coord_flip() +  # Flip coordinates for better readability
  scale_fill_gradient2(low = "firebrick3", mid = "white", high = "dodgerblue4", midpoint = 0) +
  theme_minimal() +
  labs(title = "Prediction Bias by State",
       x = "State",
       y = "Bias (%)",
       fill = "Bias (%)") +
  theme(axis.text.y = element_text(size = 8),
        legend.position = "bottom")
```

### National Two-Party Popular Vote Share Evaluation

```{r, echo = FALSE, message = FALSE, warning = FALSE}
bias <- 100*48.24/(48.24+49.96) - 56.7625280969924
cat("Bias:", bias)
```

Despite predicting the the electoral college vote share correctly, my prediction for the national two-party popular vote share went terribly wrong as of [November 18th](https://www.cookpolitical.com/vote-tracker/2024/electoral-college), where I overestimated The Democratic Party's popular vote by `r round(abs(bias), 2)` percentage points.

Therefore, I will focus on evaluating the reason for inaccuracy in my national two-party popular vote share model. I hypothesize a few reasons for my model's inaccuracy and propose corresponding changes.

**1. Unique circumstance of incumbency**

The Harris-Trump matchup presented a unique incumbency scenario: Harris was the sitting vice president, while Trump was a former president. My initial model did not fully account for this dynamic.

Change: Replace the $IncumbentPresident$ variable with $PrevAdmin$ to better capture the influence of prior administrations in such scenarios.

**2. Polling model shortcomings**

My polling model's equation is $$D\_pv2p = D\_NetLatest538PollAverage + D\_NetMean538PollAverage(30 weeks) + NetLatestJobApproval + NetMeanJobApproval(June-Oct)$$ for Democratic vote share, which I then repeat for Republican vote share separately, then rescaling them to a 100%. Predictors like net job approval and polling averages are meaningful only when used to model the incumbent party's vote share, which is not the case in my model that uses Democratic Party and Republican Party vote share as response variables.

Change: Re-run the polling model with the inclusion of dummy variables for $PrevAdmin$ and $IncumbentParty$.

**3. Poor predictability of demographics**

The demographic model exhibited high variability in out-of-sample MSE, leading to a low weight in the ensemble model.

Change: Remove demographics as a predictor variable to simplify the model and reduce variability.

```{r, echo = FALSE, message = FALSE, warning = FALSE}
### Read, merge, and process data
# Read popular vote datasets
d_vote_natl <- read_csv("popvote_1948_2020.csv")
d_vote_natl$party <- str_to_title(d_vote_natl$party)
d_vote_state <- read_csv("state_popvote_1948_2020.csv") %>% 
  mutate(D_win_lag1 = case_when(
    D_pv2p_lag1 > 50 ~ "TRUE",
    D_pv2p_lag1 < 50 ~ "FALSE"
    ))

# Read elector distribution datasets
d_ec <- read_csv("corrected_ec_1948_2024.csv") %>% 
  rename(state_abbr = stateab)

# Read economic datasets
d_fred <- read_csv("fred_econ.csv")
d_bea <- read_csv("bea_econ.csv") %>% 
  rename(year = "Year",
         quarter = "Quarter", 
         gdp = "Gross domestic product", 
         gnp = "Gross national product", 
         dpi = "Disposable personal income", 
         consumption = "Personal consumption expenditures", 
         goods = "Goods", 
         durables = "Durable goods", 
         nondurables = "Nondurable goods", 
         services = "Services", 
         pop = "Population (midperiod, thousands)")
consumer_sentiment <- read_csv("consumer_sentiment.csv") %>% 
  rename(quarter = "QUARTER",
         year = "YYYY",
         consumer_sentiment = "ICS_ALL",
         Northeast = "ICS_northeast",
         Midwest = "ICS_midwest",
         South = "ICS_south",
         West = "ICS_west") %>%
  mutate(quarter = case_when(
    quarter == "Jan.-Mar." ~ 1,
    quarter == "Apr.-June" ~ 2,
    quarter == "Jul.-Sep." ~ 3,
    quarter == "Oct.-Dec." ~ 4,
  ))
d_econ_natl <- d_vote_natl %>% 
  select(year, pv2p, party, winner) %>% 
  left_join(d_fred %>% filter(quarter == 2)) %>% 
  left_join(d_bea %>% filter(quarter == "Q2") %>% select(year, dpi)) %>% 
  left_join(consumer_sentiment %>% filter(quarter == 2) %>% select(year, consumer_sentiment))

consumer_sentiment <- consumer_sentiment %>%
  pivot_longer(
    cols = Northeast:West,
    names_to = "region",
    values_to = "consumer_sentiment_region"
  )
d_econ_state <- read_csv("econ_states.csv") %>%
  left_join(consumer_sentiment %>% filter(quarter == 2) %>% select(year, region, consumer_sentiment_region), by = c("year", "region")) # in this dataset, `unemployment` refers to change in absolute unemployment numbers rather than unemployment rate

# Read polling datasets
d_pollav_natl <- read_csv("national_polls_1968-2024.csv")
d_pollav_natl$party[d_pollav_natl$party == "DEM"] <- "Democrat"
d_pollav_natl$party[d_pollav_natl$party == "REP"] <- "Republican"

d_pollav_state <- read_csv("state_polls_1968-2024.csv")
d_pollav_state$party[d_pollav_state$party == "DEM"] <- "Democrat"
d_pollav_state$party[d_pollav_state$party == "REP"] <- "Republican"

# Read presidential job approval dataset
d_pres_approval <- read_csv("presidential_job_approval.csv") %>% 
  mutate(latest_net_approval = net_approval_oct)
d_pres_approval$mean_net_approval <- rowMeans(d_pres_approval[, c("net_approval_june", "net_approval_july", "net_approval_aug", "net_approval_sept", "net_approval_oct")], na.rm = TRUE)

### Super learning
# Merge datasets
d_natl_superlearning <- d_pollav_natl %>% 
  group_by(year, state, party) %>%
  mutate(mean_pollav = mean(poll_support)) %>%
  top_n(1, poll_date) %>% 
  rename(latest_pollav = poll_support) %>% 
  ungroup() %>% 
  group_by(year, state) %>%
  mutate(
    net_mean_pollav_D = ifelse(party == "Democrat", mean_pollav - mean_pollav[party == "Republican"], NA),
    net_latest_pollav_D = ifelse(party == "Democrat", latest_pollav - latest_pollav[party == "Republican"], NA),
    net_mean_pollav_R = ifelse(party == "Republican", mean_pollav - mean_pollav[party == "Democrat"], NA),
    net_latest_pollav_R = ifelse(party == "Republican", latest_pollav - latest_pollav[party == "Democrat"], NA)) %>% 
  ungroup() %>% 
  left_join(d_pres_approval %>% select(-incumbent_president, -party, -winner), by = c("year")) %>% 
  left_join(d_vote_natl %>% select(-pv, -candidate), by = c("year", "party")) %>% 
  left_join(d_econ_natl %>% select(-pv2p, -quarter), by = c("year", "party", "winner")) %>% 
  arrange(desc(year))

# Initialize lists to store ensemble weights and MSEs
ensemble_weights_D <- list()
in_sample_mse <- data.frame()
out_of_sample_mse <- data.frame()

# Loop through each year to compute ensemble weights and MSEs
years <- c(2020, 2016, 2012, 2008, 2004, 2000, 1996, 1992, 1988, 1984, 1980)
for (yr in years) {
  # Separate training and testing data for the out-of-sample validation
  train_data <- d_natl_superlearning %>% filter(party == "Democrat") %>% filter(year != yr)
  test_data <- d_natl_superlearning %>% filter(party == "Democrat") %>% filter(year == yr)
  
  # Model 1: Economic variables only
  sl_natl_mod_1 <- lm(pv2p ~ unemployment + GDP_growth_quarterly + sp500_volume + consumer_sentiment + RDPI_growth_quarterly, data = train_data)
  in_sample_pred_1 <- predict(sl_natl_mod_1, newdata = train_data)
  out_sample_pred_1 <- predict(sl_natl_mod_1, newdata = test_data)
  
  # Model 2: Polling averages and presidential job approval only 
  sl_natl_mod_2 <- lm(pv2p ~ net_latest_pollav_D + net_mean_pollav_D + latest_net_approval + mean_net_approval + incumbent_party + prev_admin, data = train_data)
  in_sample_pred_2 <- predict(sl_natl_mod_2, newdata = train_data)
  out_sample_pred_2 <- predict(sl_natl_mod_2, newdata = test_data)
  
  # Model 4: Combined models
  sl_natl_mod_3 <- lm(pv2p ~ incumbent_party + prev_admin + unemployment + GDP_growth_quarterly + sp500_volume + consumer_sentiment + RDPI_growth_quarterly + net_latest_pollav_D + net_mean_pollav_D + latest_net_approval + mean_net_approval, data = train_data)
  in_sample_pred_3 <- predict(sl_natl_mod_3, newdata = train_data)
  out_sample_pred_3 <- predict(sl_natl_mod_3, newdata = test_data)
  
  # Prepare data for ensemble weight calculation
  d_weight <- data.frame(
    "truth" = test_data$pv2p,
    "economy" = out_sample_pred_1,
    "polling" = out_sample_pred_2,
    "combo" = out_sample_pred_3
  )
  
  # Constrained optimization for ensemble model weights
  c <- 3 # number of models
  predictions <- cbind(out_sample_pred_1, out_sample_pred_2, out_sample_pred_3)
  y_test <- d_weight$truth
  beta <- Variable(c)
  objective <- Minimize(sum_squares(y_test - predictions %*% beta))
  constraints <- list(beta >= 0, sum(beta) == 1)
  prob <- Problem(objective, constraints)
  solution_prob <- solve(prob)
  weights <- as.numeric(solution_prob$getValue(beta))

  # Store weights for each year
  ensemble_weights_D[[as.character(yr)]] <- weights

  # Calculate the ensemble predictions using the weights
  in_sample_ensemble_pred_D <- weights[1] * in_sample_pred_1 + weights[2] * in_sample_pred_2 + weights[3] * in_sample_pred_3
  out_sample_ensemble_pred_D <- weights[1] * out_sample_pred_1 + weights[2] * out_sample_pred_2 + weights[3] * out_sample_pred_3
  
  # Calculate and store MSEs
  in_sample_mse <- rbind(in_sample_mse, data.frame(
    Year = yr,
    Economy_Model_MSE = mean((train_data$pv2p - in_sample_pred_1)^2, na.rm = TRUE),
    Polling_Model_MSE = mean((train_data$pv2p - in_sample_pred_2)^2, na.rm = TRUE),
    Combined_Model_MSE = mean((train_data$pv2p - in_sample_pred_3)^2, na.rm = TRUE),
    Ensemble_Model_MSE = mean((train_data$pv2p - in_sample_ensemble_pred_D)^2, na.rm = TRUE)
  ))
  
  out_of_sample_mse <- rbind(out_of_sample_mse, data.frame(
    Year = yr,
    Economy_Model_MSE = mean((test_data$pv2p - out_sample_pred_1)^2, na.rm = TRUE),
    Polling_Model_MSE = mean((test_data$pv2p - out_sample_pred_2)^2, na.rm = TRUE),
    Combined_Model_MSE = mean((test_data$pv2p - out_sample_pred_3)^2, na.rm = TRUE),
    Ensemble_Model_MSE = mean((test_data$pv2p - out_sample_ensemble_pred_D)^2, na.rm = TRUE)
  ))
}

# Combine weights for each year into a data frame
weights_df <- do.call(rbind, ensemble_weights_D) %>% 
  as.data.frame() %>% 
  setNames(c("Economy Weight", "Polling Weight", "Combined Weight"))
weights_df$Year <- years

# Combine tables into one final table
combined_mse_weights <- in_sample_mse %>%
  full_join(out_of_sample_mse, by = "Year", suffix = c("_in_sample", "_out_of_sample")) %>%
  full_join(weights_df, by = "Year")

# Display the merged table with colored columns
kable(combined_mse_weights,
      col.names = c("Year", 
                    "In-Sample Economy MSE", "In-Sample Polling MSE", "In-Sample Combined MSE", "In-Sample Ensemble MSE",
                    "Out-of-Sample Economy MSE", "Out-of-Sample Polling MSE", "Out-of-Sample Combined MSE", "Out-of-Sample Ensemble MSE",
                    "Economy Weight", "Polling Weight", "Combined Weight"),
      caption = "In-Sample and Out-of-Sample MSEs with Ensemble Weights by Year (National)",
      format = "html") %>%
  kable_styling(full_width = FALSE) %>%
  column_spec(2:5, background = "lightgreen") %>%
  column_spec(6:9, background = "violet") %>%
  column_spec(10:12, background = "yellow")

### Super learning to get weights for Republican
d_natl_superlearning <- d_pollav_natl %>% 
  group_by(year, state, party) %>%
  mutate(mean_pollav = mean(poll_support)) %>%
  top_n(1, poll_date) %>% 
  rename(latest_pollav = poll_support) %>% 
  ungroup() %>% 
  group_by(year, state) %>%
  mutate(
    net_mean_pollav_D = ifelse(party == "Democrat", mean_pollav - mean_pollav[party == "Republican"], NA),
    net_latest_pollav_D = ifelse(party == "Democrat", latest_pollav - latest_pollav[party == "Republican"], NA),
    net_mean_pollav_R = ifelse(party == "Republican", mean_pollav - mean_pollav[party == "Democrat"], NA),
    net_latest_pollav_R = ifelse(party == "Republican", latest_pollav - latest_pollav[party == "Democrat"], NA)) %>% 
  ungroup() %>% 
  left_join(d_pres_approval %>% select(-incumbent_president, -party, -winner), by = c("year")) %>% 
  left_join(d_vote_natl %>% select(-pv, -candidate), by = c("year", "party")) %>% 
  left_join(d_econ_natl %>% select(-pv2p, -quarter), by = c("year", "party", "winner")) %>% 
  arrange(desc(year))
ensemble_weights_R <- list()
years <- c(2020, 2016, 2012, 2008, 2004, 2000, 1996, 1992, 1988, 1984, 1980)
for (yr in years) {
  # Separate training and testing data for the out-of-sample validation
  train_data <- d_natl_superlearning %>% filter(party == "Republican") %>% filter(year != yr)
  test_data <- d_natl_superlearning %>% filter(party == "Republican") %>% filter(year == yr)
  
  # Model 1: Economic variables only
  sl_natl_mod_1 <- lm(pv2p ~ unemployment + GDP_growth_quarterly + sp500_volume + consumer_sentiment + RDPI_growth_quarterly, data = train_data)
  in_sample_pred_1 <- predict(sl_natl_mod_1, newdata = train_data)
  out_sample_pred_1 <- predict(sl_natl_mod_1, newdata = test_data)
  
  # Model 2: Polling averages and presidential job approval only 
  sl_natl_mod_2 <- lm(pv2p ~ net_latest_pollav_R + net_mean_pollav_R + latest_net_approval + mean_net_approval + incumbent_party + prev_admin, data = train_data)
  in_sample_pred_2 <- predict(sl_natl_mod_2, newdata = train_data)
  out_sample_pred_2 <- predict(sl_natl_mod_2, newdata = test_data)
  
  # Model 3: Combined models
  sl_natl_mod_3 <- lm(pv2p ~ incumbent_party + prev_admin + unemployment + GDP_growth_quarterly + sp500_volume + consumer_sentiment + RDPI_growth_quarterly + net_latest_pollav_R + net_mean_pollav_R + latest_net_approval + mean_net_approval, data = train_data)
  in_sample_pred_3 <- predict(sl_natl_mod_3, newdata = train_data)
  out_sample_pred_3 <- predict(sl_natl_mod_3, newdata = test_data)
  
  # Prepare data for ensemble weight calculation
  d_weight <- data.frame(
    "truth" = test_data$pv2p,
    "economy" = out_sample_pred_1,
    "polling" = out_sample_pred_2,
    "combo" = out_sample_pred_3
  )
  
  # Constrained optimization for ensemble model weights
  c <- 3 # number of models
  predictions <- cbind(out_sample_pred_1, out_sample_pred_2, out_sample_pred_3)
  y_test <- d_weight$truth
  beta <- Variable(c)
  objective <- Minimize(sum_squares(y_test - predictions %*% beta))
  constraints <- list(beta >= 0, sum(beta) == 1)
  prob <- Problem(objective, constraints)
  solution_prob <- solve(prob)
  weights <- as.numeric(solution_prob$getValue(beta))
  
  # Store weights for each year
  ensemble_weights_R[[as.character(yr)]] <- weights
  
  # Calculate the ensemble predictions using the weights
  in_sample_ensemble_pred_R <- weights[1] * in_sample_pred_1 + weights[2] * in_sample_pred_2 + weights[3] * in_sample_pred_3
  out_sample_ensemble_pred_R <- weights[1] * out_sample_pred_1 + weights[2] * out_sample_pred_2 + weights[3] * out_sample_pred_3
}

### National level prediction
# Subset 2024 data for both parties
test_data_2024_D <- d_natl_superlearning %>% filter(party == "Democrat") %>% filter(year == 2024)
test_data_2024_R <- d_natl_superlearning %>% filter(party == "Republican") %>% filter(year == 2024)

# Set up bootstrap sampling
set.seed(321)
n_bootstraps <- 1000
bootstrap_preds_D <- numeric(n_bootstraps)
bootstrap_preds_R <- numeric(n_bootstraps)

for (i in 1:n_bootstraps) {
  # Sample with replacement from training data to create a bootstrap sample for Democrats
  bootstrap_sample_D <- d_natl_superlearning %>% filter(party == "Democrat") %>% sample_frac(replace = TRUE)
  
  # Fit each model to the bootstrap sample for Democrats
  bootstrap_mod_1_D <- lm(pv2p ~ unemployment + GDP_growth_quarterly + sp500_volume + consumer_sentiment + RDPI_growth_quarterly, data = bootstrap_sample_D)
  bootstrap_mod_2_D <- lm(pv2p ~ net_latest_pollav_D + net_mean_pollav_D + latest_net_approval + mean_net_approval + incumbent_party + prev_admin, data = bootstrap_sample_D)
  bootstrap_mod_3_D <- lm(pv2p ~ incumbent_party + prev_admin + unemployment + GDP_growth_quarterly + sp500_volume + consumer_sentiment + RDPI_growth_quarterly + latest_pollav + mean_pollav + latest_net_approval + mean_net_approval, data = bootstrap_sample_D)
  
  # Get predictions for each model using 2024 Democrat test data
  pred_1_D <- predict(bootstrap_mod_1_D, newdata = test_data_2024_D)
  pred_2_D <- predict(bootstrap_mod_2_D, newdata = test_data_2024_D)
  pred_3_D <- predict(bootstrap_mod_3_D, newdata = test_data_2024_D)
  
  # Combine predictions using average weights for Democrat
  predictions_2024_D <- cbind(pred_1_D, pred_2_D, pred_3_D)
  average_weights_D <- colMeans(do.call(rbind, ensemble_weights_D))
  bootstrap_preds_D[i] <- as.numeric(t(average_weights_D) %*% t(predictions_2024_D))
  
  # Repeat the process for Republicans
  bootstrap_sample_R <- d_natl_superlearning %>% filter(party == "Republican") %>% sample_frac(replace = TRUE)
  
  # Fit each model to the bootstrap sample for Republicans
  bootstrap_mod_1_R <- lm(pv2p ~ unemployment + GDP_growth_quarterly + sp500_volume + consumer_sentiment + RDPI_growth_quarterly, data = bootstrap_sample_R)
  bootstrap_mod_2_R <- lm(pv2p ~ net_latest_pollav_R + net_mean_pollav_R + latest_net_approval + mean_net_approval + incumbent_party + prev_admin, data = bootstrap_sample_R)
  bootstrap_mod_3_R <- lm(pv2p ~ incumbent_party + prev_admin + unemployment + GDP_growth_quarterly + sp500_volume + consumer_sentiment + RDPI_growth_quarterly + latest_pollav + mean_pollav + latest_net_approval + mean_net_approval, data = bootstrap_sample_R)
  
  # Get predictions for each model using 2024 Republican test data
  pred_1_R <- predict(bootstrap_mod_1_R, newdata = test_data_2024_R)
  pred_2_R <- predict(bootstrap_mod_2_R, newdata = test_data_2024_R)
  pred_3_R <- predict(bootstrap_mod_3_R, newdata = test_data_2024_R)
  
  # Combine predictions using average weights for Republican
  predictions_2024_R <- cbind(pred_1_R, pred_2_R, pred_3_R)
  average_weights_R <- colMeans(do.call(rbind, ensemble_weights_R))
  bootstrap_preds_R[i] <- as.numeric(t(average_weights_R) %*% t(predictions_2024_R))
}

# Calculate the mean and 90% predictive interval for Democrat and Republican predictions
mean_pred_D <- mean(bootstrap_preds_D)
lower_bound_D <- quantile(bootstrap_preds_D, 0.05)
upper_bound_D <- quantile(bootstrap_preds_D, 0.95)

mean_pred_R <- mean(bootstrap_preds_R)
lower_bound_R <- quantile(bootstrap_preds_R, 0.05)
upper_bound_R <- quantile(bootstrap_preds_R, 0.95)

# Convert bootstrap predictions to a data frame for ggplot with party labels
bootstrap_df <- data.frame(
  prediction = c(bootstrap_preds_D, bootstrap_preds_R),
  party = rep(c("Democrat", "Republican"), each = n_bootstraps)
)

# Create the overlapping histograms with ggplot
ggplot(bootstrap_df, aes(x = prediction, fill = party)) +
  geom_histogram(data = subset(bootstrap_df, party == "Democrat"), binwidth = 0.5, fill = "lightblue", alpha = 0.6) +
  geom_histogram(data = subset(bootstrap_df, party == "Republican"), binwidth = 0.5, fill = "lightpink", alpha = 0.6) +
  geom_vline(aes(xintercept = mean_pred_D), color = "dodgerblue4", linetype = "dashed", size = 1) +
  geom_vline(aes(xintercept = mean_pred_R), color = "firebrick", linetype = "dashed", size = 1) +
  labs(title = "Prediction for 2024 Vote Share by Party",
       x = "Predicted Vote Share (%)",
       y = "Frequency") +
  scale_x_continuous(limits = c(20, 70)) +
  scale_fill_manual(values = c("Democrat" = "lightblue", "Republican" = "lightpink")) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        legend.position = "top") +
  annotate("text", x = mean_pred_D, y = 10, label = "         Mean Prediction (Democrat)", color = "dodgerblue4", angle = 90, vjust = -0.5) +
  annotate("text", x = mean_pred_R, y = 10, label = "           Mean Prediction (Republican)", color = "firebrick3", angle = 90, vjust = -0.5)

# Rescale predicted vote shares to a total of 100%
rescaled_pred_D <- (mean_pred_D / (mean_pred_D + mean_pred_R)) * 100
rescaled_pred_R <- (mean_pred_R / (mean_pred_D + mean_pred_R)) * 100
rescaled_lower_D <- (lower_bound_D / (lower_bound_D + lower_bound_R)) * 100
rescaled_upper_D <- (upper_bound_D / (upper_bound_D + upper_bound_R)) * 100
rescaled_lower_R <- (lower_bound_R / (lower_bound_D + lower_bound_R)) * 100
rescaled_upper_R <- (upper_bound_R / (upper_bound_D + upper_bound_R)) * 100

# Update ensemble_pred_2024 with rescaled predictions
ensemble_pred_2024 <- data.frame(year = 2024,
                                 party = c("Democrat", "Republican"),
                                 pred = c(rescaled_pred_D, rescaled_pred_R),
                                 winner = c(rescaled_pred_D > 50, rescaled_pred_R > 50))

# Display the final rescaled prediction using knitr::kable and kableExtra
kable(ensemble_pred_2024, 
      col.names = c("Year", "Party", "Predicted Vote Share (%)", "Winner"),
      format = "html") %>%
  kable_styling(full_width = FALSE) %>%
  row_spec(which(ensemble_pred_2024$party == "Democrat"), background = "lightblue") %>%
  row_spec(which(ensemble_pred_2024$party == "Republican"), background = "lightpink")

bias_modified <- 100*48.24/(48.24+49.96) - rescaled_pred_D
cat("Bias:", bias_modified)
```

Incorporating the changes above, my revised model predicted the national two-party popular vote share with `r round(abs(bias_modified), 2)` percentage points error.

Other than the changes I have done above, I propose future modifications for election prediction models.

**1. Accounting for voter turnout**

Hypothesis: Lower turnout among traditionally Democratic voters, possibly due to dissatisfaction with the administration’s handling of difficult issues such as the [Gaza conflict](https://www.reuters.com/world/us/inside-democratic-rebellion-against-biden-over-gaza-war-2024-02-27/), reduced Harris's vote share.

Test: Compare turnout rates by demographic groups in 2024 to previous elections using voter file data and assess whether historically Democratic demographics (such as younger voters and minority ethnic groups) had a decline in turnout.

**2. Economic reality versus perception**

I will incorporate economic variables that more accurately measures voters' perception of the economy, as [people might still be recovering from the impact of COVID-19 economic downturn](https://www.cnn.com/2024/02/02/politics/cnn-poll-economy/index.html), so unemployment, GDP and RDPI figures may not reflect the full extent of how voters perceive the economy.

Hypothesis: My economic predictors (such as unemployment, GDP, S&P 500 volume, and real disposable personal income) failed to capture voters' subjective perceptions of the economy. For example, while unemployment rates were low, the impact of food price inflation or the lingering effects of the COVID-19 pandemic might have weighed more heavily on voters' decisions, given that [April 2022 food prices inflation rate rose up to 10.8%](https://www.bls.gov/opub/ted/2022/food-prices-up-10-8-percent-for-year-ended-april-2022-largest-12-month-increase-since-november-1980.htm#:~:text=FONT%20SIZE:%20PRINT:-,Food%20prices%20up%2010.8%20percent%20for%20year%20ended%20April%202022,month%20increase%20since%20November%201980&text=For%20the%20year%20ended%20April,percent%20increase%20in%20November%201981.), for instance.

Test: Analyze survey data on voters’ perception of economic conditions and correlate these perceptions with vote choices.

I will also expand economic variables:
- Use additional economic predictors, such as food price inflation and median wage growth, to capture the direct impact of economic stressors on voters.
- Extend the time frame for economic data to include the entire incumbent party’s term, not just the election year, as significantly poor economic conditions in 2022 and 2023 may have caused voter dissatistaction which carried on to 2024.

**3. Adjusting for airwar according to latest trends**

Hypothesis: While traditional airwar analysis focuses on campaign spending on television advertisements, modern media platforms such as podcasts, social media, and celebrity endorsements may play a significant role in shaping public opinion, especially among younger voters who are tech-savvy or older voters who have a lot of time to spend on their devices. For example, [Trump's appearance on Joe Rogan's podcast](https://www.thetimes.com/life-style/celebrity/article/donald-trump-joe-rogan-8grmztcjn), [Harris's endorsement by Taylor Swift](https://www.nbcnews.com/politics/2024-election/taylor-swift-endorses-kamala-harris-rcna170547), or interactions on platforms like FaceBook, Instagram and TikTok may influence voter sentiment in ways that are not captured by traditional ad spending metrics.

Test: Collect data on the following metrics and compare them to the candidates' vote share in specific demographic groups (such as younger voters) to evaluate their predictive power.

Metrics include:
- Audience size for each candidate's media appearances on platforms such as podcasts, late-night shows, and endorsements by public figures
- Engagement metrics such as the number of likes, shares, and comments for content related to each candidate
- Sentiment analysis of audience comments using natural language processing to assess voter sentiment

```{r, echo = FALSE, message = FALSE, warning = FALSE, include = FALSE}
### Unused codes

### Visualize county winners
# Make map of county winners.
ggplot(counties_2024, aes(fill = factor(winner))) + 
  geom_sf() + 
  scale_fill_manual(values = c("Democrat" = "dodgerblue4", "Republican" = "firebrick3")) + 
  theme_minimal() + 
  labs(title = "2024 Presidential Election Results by County", 
       fill = "Winner") + 
  theme(legend.position = "bottom")

### Visualize county-level shifts
# Make arrow map of county-level shifts across US. 
counties_2024$shift %>% mean()
counties_2024 %>% 
  ggplot() +
  geom_sf(fill = "gray95", color = "darkgrey") +  # Base map
  geom_curve(aes(x = centroid_long, 
                 y = centroid_lat,
                 xend = end_long, 
                 yend = end_lat,
                 color = shift_dir),
              arrow = arrow(length = unit(0.1, "cm"), type = "closed"),  # Smaller arrowhead
              curvature = 0.2,  # Add a slight curve to each arrow
              size = 0.2) +
  scale_color_manual(values = c("Democrat" = "dodgerblue4", "Republican" = "firebrick")) +
  theme_void() +
  labs(title = "Presidential Voting Shifts by County Across the US",
       subtitle = "Democratic vs. Republican Gains")

# Check county-level shifts in Pennsylvania between 2024 and 2020. 
counties_2024 %>% 
  filter(STATE_NAME == "Pennsylvania") %>% 
  ggplot() +
  geom_sf(fill = "gray95", color = "darkgrey") +  # Base map
  geom_text(aes(x = centroid_long, y = centroid_lat-1e4, label = NAME),
            size = 2,  # Adjust size as needed
            color = "black", hjust = 0.5, vjust = -0.5) + 
  geom_curve(aes(x = centroid_long, 
                 y = centroid_lat,
                 xend = end_long, 
                 yend = end_lat,
                 color = shift_dir),
             arrow = arrow(length = unit(0.1, "cm"), type = "closed"),  # Smaller arrowhead
             curvature = 0.2,  # Add a slight curve to each arrow
             size = 0.3) +
  scale_color_manual(values = c("Democrat" = "dodgerblue4", "Republican" = "firebrick")) +
  theme_void() +
  labs(title = "Presidential Voting Shifts by County in Pennsylvania",
       subtitle = "Democratic vs. Republican Gains")

# Check county-level shifts in Arizona between 2024 and 2020. 
counties_2024 %>% 
  filter(STATE_NAME == "Arizona") %>% 
  ggplot() +
  geom_sf(fill = "gray95", color = "darkgrey") +  # Base map
  geom_text(aes(x = centroid_long, y = centroid_lat-1.5e4, label = NAME),
            size = 2,  # Adjust size as needed
            color = "black", hjust = 0.5, vjust = -0.5) + 
  geom_curve(aes(x = centroid_long, 
                 y = centroid_lat,
                 xend = end_long, 
                 yend = end_lat,
                 color = shift_dir),
             arrow = arrow(length = unit(0.1, "cm"), type = "closed"),  # Smaller arrowhead
             curvature = 0.2,  # Add a slight curve to each arrow
             size = 0.3) +
  scale_color_manual(values = c("Democrat" = "dodgerblue4", "Republican" = "firebrick")) +
  theme_void() +
  labs(title = "Presidential Voting Shifts by County in Arizona",
       subtitle = "Democratic vs. Republican Gains")

# Check county-level shifts in Nevada between 2024 and 2020. 
counties_2024 %>% 
  filter(STATE_NAME == "Nevada") %>% 
  ggplot() +
  geom_sf(fill = "gray95", color = "darkgrey") +  # Base map
  geom_text(aes(x = centroid_long, y = centroid_lat-2e4, label = NAME),
            size = 2,  # Adjust size as needed
            color = "black", hjust = 0.5, vjust = -0.5) + 
  geom_curve(aes(x = centroid_long, 
                 y = centroid_lat,
                 xend = end_long, 
                 yend = end_lat,
                 color = shift_dir),
             arrow = arrow(length = unit(0.1, "cm"), type = "closed"),  # Smaller arrowhead
             curvature = 0.2,  # Add a slight curve to each arrow
             size = 0.3) +
  scale_color_manual(values = c("Democrat" = "dodgerblue4", "Republican" = "firebrick")) +
  theme_void() +
  labs(title = "Presidential Voting Shifts by County in Nevada",
       subtitle = "Democratic vs. Republican Gains")

# Check county-level shifts in Florida between 2024 and 2020. 
counties_2024 %>% 
  filter(STATE_NAME == "Florida") %>% 
  ggplot() +
  geom_sf(fill = "gray95", color = "darkgrey") +  # Base map
  geom_text(aes(x = centroid_long, y = centroid_lat-1.6e4, label = NAME),
            size = 2,  # Adjust size as needed
            color = "black", hjust = 0.5, vjust = -0.5) + 
  geom_curve(aes(x = centroid_long, 
                 y = centroid_lat,
                 xend = end_long, 
                 yend = end_lat,
                 color = shift_dir),
             arrow = arrow(length = unit(0.1, "cm"), type = "closed"),  # Smaller arrowhead
             curvature = 0.2,  # Add a slight curve to each arrow
             size = 0.3) +
  scale_color_manual(values = c("Democrat" = "dodgerblue4", "Republican" = "firebrick")) +
  theme_void() +
  labs(title = "Presidential Voting Shifts by County in Florida",
       subtitle = "Democratic vs. Republican Gains")

# Check county-level shifts in California between 2024 and 2020. 
counties_2024 %>% 
  filter(STATE_NAME == "California") %>% 
  ggplot() +
  geom_sf(fill = "gray95", color = "darkgrey") +  # Base map
  geom_text(aes(x = centroid_long, y = centroid_lat-2.6e4, label = NAME),
            size = 2,  # Adjust size as needed
            color = "black", hjust = 0.5, vjust = -0.5) + 
  geom_curve(aes(x = centroid_long, 
                 y = centroid_lat,
                 xend = end_long, 
                 yend = end_lat,
                 color = shift_dir),
             arrow = arrow(length = unit(0.1, "cm"), type = "closed"),  # Smaller arrowhead
             curvature = 0.2,  # Add a slight curve to each arrow
             size = 0.3) +
  scale_color_manual(values = c("Democrat" = "dodgerblue4", "Republican" = "firebrick")) +
  theme_void() +
  labs(title = "Presidential Voting Shifts by County in California",
       subtitle = "Democratic vs. Republican Gains")

# Check county-level shifts in Michigan between 2024 and 2020. 
counties_2024 %>% 
  filter(STATE_NAME == "Michigan") %>% 
  ggplot() +
  geom_sf(fill = "gray95", color = "darkgrey") +  # Base map
  geom_text(aes(x = centroid_long, y = centroid_lat-1e4, label = NAME),
            size = 1.7,  # Adjust size as needed
            color = "black", hjust = 0.5, vjust = -0.5) + 
  geom_curve(aes(x = centroid_long, 
                 y = centroid_lat,
                 xend = end_long, 
                 yend = end_lat,
                 color = shift_dir),
             arrow = arrow(length = unit(0.1, "cm"), type = "closed"),  # Smaller arrowhead
             curvature = 0.2,  # Add a slight curve to each arrow
             size = 0.3) +
  scale_color_manual(values = c("Democrat" = "dodgerblue4", "Republican" = "firebrick")) +
  theme_void() +
  labs(title = "Presidential Voting Shifts by County in Michigan",
       subtitle = "Democratic vs. Republican Gains")

# Check county-level shifts in Wisconsin between 2024 and 2020. 
counties_2024 %>% 
  filter(STATE_NAME == "Wisconsin") %>% 
  ggplot() +
  geom_sf(fill = "gray95", color = "darkgrey") +  # Base map
  geom_text(aes(x = centroid_long, y = centroid_lat-1.5e4, label = NAME),
            size = 1.8,  # Adjust size as needed
            color = "black", hjust = 0.5, vjust = -0.5) + 
  geom_curve(aes(x = centroid_long, 
                 y = centroid_lat,
                 xend = end_long, 
                 yend = end_lat,
                 color = shift_dir),
             arrow = arrow(length = unit(0.1, "cm"), type = "closed"),  # Smaller arrowhead
             curvature = 0.2,  # Add a slight curve to each arrow
             size = 0.3) +
  scale_color_manual(values = c("Democrat" = "dodgerblue4", "Republican" = "firebrick")) +
  theme_void() +
  labs(title = "Presidential Voting Shifts by County in Wisconsin",
       subtitle = "Democratic vs. Republican Gains")

# Check county-level shifts in Georgia between 2024 and 2020. 
counties_2024 %>% 
  filter(STATE_NAME == "Georgia") %>% 
  ggplot() +
  geom_sf(fill = "gray95", color = "darkgrey") +  # Base map
  geom_text(aes(x = centroid_long, y = centroid_lat-1e4, label = NAME),
            size = 1.5,  # Adjust size as needed
            color = "black", hjust = 0.5, vjust = -0.5) + 
  geom_curve(aes(x = centroid_long, 
                 y = centroid_lat,
                 xend = end_long, 
                 yend = end_lat,
                 color = shift_dir),
             arrow = arrow(length = unit(0.1, "cm"), type = "closed"),  # Smaller arrowhead
             curvature = 0.2,  # Add a slight curve to each arrow
             size = 0.3) +
  scale_color_manual(values = c("Democrat" = "dodgerblue4", "Republican" = "firebrick")) +
  theme_void() +
  labs(title = "Presidential Voting Shifts by County in Georgia",
       subtitle = "Democratic vs. Republican Gains")

# Check county-level shifts in North Carolina between 2024 and 2020. 
counties_2024 %>% 
  filter(STATE_NAME == "North Carolina") %>% 
  ggplot() +
  geom_sf(fill = "gray95", color = "darkgrey") +  # Base map
  geom_text(aes(x = centroid_long, y = centroid_lat-1e4, label = NAME),
            size = 1.5,  # Adjust size as needed
            color = "black", hjust = 0.5, vjust = -0.5) + 
  geom_curve(aes(x = centroid_long, 
                 y = centroid_lat,
                 xend = end_long, 
                 yend = end_lat,
                 color = shift_dir),
             arrow = arrow(length = unit(0.1, "cm"), type = "closed"),  # Smaller arrowhead
             curvature = 0.2,  # Add a slight curve to each arrow
             size = 0.3) +
  scale_color_manual(values = c("Democrat" = "dodgerblue4", "Republican" = "firebrick")) +
  theme_void() +
  labs(title = "Presidential Voting Shifts by County in North Carolina",
       subtitle = "Democratic vs. Republican Gains")
```
